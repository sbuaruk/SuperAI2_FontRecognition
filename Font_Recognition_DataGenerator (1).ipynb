{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Font_Recognition_DataGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download training dataset"
      ],
      "metadata": {
        "id": "dFY8Orpj_ujk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Note that the training data is pre-processed by N'Sarm.\n",
        "- Since we, team Optimizer-6, have discussed with all minor teams in House-Optimizer and we agreed with size problem of text from each bounding box.\n",
        " - We tried to check the image size, considered from the distribution of width and height dimensions.\n",
        " - We found that most of images, contain 100-200 pixels for width and heights. \n",
        "- The brief idea is normalizing all images, cropping from bounding box, to keep features related to image sizes.\n",
        " - The solution is placing the cropped image onto new background with same size, 105x105 components in this case.\n",
        " - This size is not magic number but we decided to use them because the chosen model architecture.\n",
        " - From team discussion, we firstly focused on DeepFont model which requires 105x105 pixels for the input images. \n",
        "- All images are processed by resize based on original dimensions\n",
        " - if old_height <= 105 and old_width <= 105:\n",
        " - elif old_height <= 105 and old_width > 105:\n",
        " - elif old_height > 105 and old_width <= 105:\n",
        " - else:\n",
        "- Then, they are processed as follows:\n",
        " - converts to grayscale\n",
        " - GaussianBlur\n",
        " - adaptiveThreshold\n",
        " - binarized by threshold_sauvola\n"
      ],
      "metadata": {
        "id": "w_GoNaDhP8yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# zip file from Optimizer-5 (Sauvola)\n",
        "!gdown --id 1mBr6_Q_cvqPgYMlzCLK7dB202wTsLjnQ&export=download"
      ],
      "metadata": {
        "id": "Bm9BYdOe_0hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/Thresh_Sauvola.zip -d /content/"
      ],
      "metadata": {
        "id": "wwU22egB_2uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split train data into train and validation data folder"
      ],
      "metadata": {
        "id": "hNjvTJGO_6MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "nD-7Z5Rm797c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAIN_PATH = '/content/Thresh_Sauvola'\n",
        "files = os.listdir(\"/content/Thresh_Sauvola\")\n",
        "\n",
        "# label for each class\n",
        "name_label = ['Angsana_New', 'Cordia_New', 'DM_Shining_Star_Regular',  \n",
        "              'FC_Knomphing_Regular', 'Kunlasatri', 'TH_Chakra_Petch',\n",
        "              'TH_Charm_of_AU', 'TH_Mali_Grade6', 'TH_Sarabun', 'fonttintin']\n",
        "size_label = ['12', '14', '16', '18', '20', '22', '24']\n",
        "style_label = ['italic-bold', 'italic-normal', 'normal-bold', 'normal-normal']\n",
        "\n",
        "\n",
        "# for font family and font style\n",
        "for file in files:\n",
        "  image_path = os.path.join(MAIN_PATH, file)\n",
        "  \n",
        "  for label in name_label:\n",
        "    if not os.path.isdir('Train/' + label):\n",
        "      os.makedirs('Train/' + label)\n",
        "\n",
        "    if label in file:\n",
        "      shutil.move(image_path, 'Train/' + label)\n",
        "\n",
        "# NOTE: Since font size number, 12_14_16_18_20_22_24, is sometimes found in ParentId \n",
        "# for font size\n",
        "# for file in files:\n",
        "#   image_path = os.path.join(MAIN_PATH, file)\n",
        "  \n",
        "#   for label in size_label:\n",
        "#     if not os.path.isdir('Train/' + label):\n",
        "#       os.makedirs('Train/' + label)\n",
        "\n",
        "#     if label in file.split('-')[1]:\n",
        "#       shutil.move(image_path, 'Train/' + label)"
      ],
      "metadata": {
        "id": "vH5QPUwV8Nic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define function for splitting the initial training data into train and validation dataset\n",
        "def split_data(path_to_data, path_to_save_train, path_to_save_val, split_size=0.3):\n",
        "    \n",
        "    folders = os.listdir(path_to_data)\n",
        "    \n",
        "    for folder in folders:\n",
        "        \n",
        "        full_path = os.path.join(path_to_data, folder)\n",
        "        images_paths = glob.glob(os.path.join(full_path, '*.jpg'))\n",
        "        \n",
        "        x_train, x_val = train_test_split(images_paths, test_size = split_size)\n",
        "        \n",
        "        for x in x_train:\n",
        "            \n",
        "            path_to_folder = os.path.join(path_to_save_train, folder)\n",
        "            \n",
        "            if not os.path.isdir(path_to_folder):\n",
        "                os.makedirs(path_to_folder)\n",
        "                \n",
        "            shutil.copy(x, path_to_folder)\n",
        "            \n",
        "        for x in x_val:\n",
        "            \n",
        "            path_to_folder = os.path.join(path_to_save_val, folder)\n",
        "            if not os.path.isdir(path_to_folder):\n",
        "                os.makedirs(path_to_folder)\n",
        "                \n",
        "            shutil.copy(x, path_to_folder)"
      ],
      "metadata": {
        "id": "7oO2CDsJ_tsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define path for moving data into train and validation folder\n",
        "PATH_main = \"/content\"\n",
        "\n",
        "path_to_data = os.path.join(PATH_main, \"Train\")\n",
        "path_to_save_train = os.path.join(PATH_main, \"training_data/train\")\n",
        "path_to_save_val = os.path.join(PATH_main, \"training_data/val\")\n",
        "    \n",
        "split_data(path_to_data,  \n",
        "           path_to_save_train=path_to_save_train,  \n",
        "           path_to_save_val=path_to_save_val)"
      ],
      "metadata": {
        "id": "XLFvG5b9BLX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a NN the functional way"
      ],
      "metadata": {
        "id": "aeO4JZ5GBz_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import labraries for NN architecture\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.layers import Conv2D, Input, Dense, MaxPool2D, BatchNormalization, GlobalAvgPool2D, Flatten, Dropout\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from keras.models import Sequential \n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger"
      ],
      "metadata": {
        "id": "2FtDuS5VCB0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model architecture: InceptionV3 (transfer learning)\n",
        "def class_model(nbr_classes):\n",
        "  \n",
        "  # Note that the input shape equals to (105,105,3)\n",
        "  inception = InceptionV3(include_top=False, weights='imagenet', input_shape=(105, 105, 3))\n",
        "  model = Sequential()\n",
        "  model.add(inception)\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(100,activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(nbr_classes,activation='softmax'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "huiq0GCiCPJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # model architecture: simple CNN\n",
        "# def class_model(nbr_classes):\n",
        "\n",
        "#   my_input = Input(shape=(105, 105, 3))\n",
        "\n",
        "#   x = Conv2D(32, (3,3), activation='relu')(my_input)\n",
        "#   x = MaxPool2D()(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "\n",
        "#   x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "#   x = MaxPool2D()(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "\n",
        "#   x = Conv2D(128, (3,3), activation='relu')(x)\n",
        "#   x = MaxPool2D()(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "\n",
        "#   x = GlobalAvgPool2D()(x)\n",
        "#   x = Dense(128, activation='relu')(x)\n",
        "#   x = Dense(nbr_classes, activation='softmax')(x)\n",
        "\n",
        "#   return tf.keras.Model(inputs=my_input,  \n",
        "#                outputs=x)"
      ],
      "metadata": {
        "id": "3wuvM-17GkVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class_model(10).summary()"
      ],
      "metadata": {
        "id": "1Jq1hCAqIQ-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "# Plot model graph\n",
        "plot_model(class_model(10), show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(retina=True, filename='model.png')"
      ],
      "metadata": {
        "id": "ZQL_ql_vEz3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Datagenerator"
      ],
      "metadata": {
        "id": "lxzSpHCSFuD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "9oJgr9gPFwav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_generators(batch_size, train_data_path, val_data_path):\n",
        "\n",
        "  train_preprocessor = ImageDataGenerator(\n",
        "      rescale = 1 / 255.,\n",
        "      # rotation_range = 10,      # Potential improvements\n",
        "      # width_shift_range=0.1     # Potential improvements\n",
        "  )\n",
        "\n",
        "  test_preprocessor = ImageDataGenerator(\n",
        "      rescale = 1 / 255.,\n",
        "  )\n",
        "\n",
        "  train_generator = train_preprocessor.flow_from_directory(\n",
        "      train_data_path,  \n",
        "      class_mode='categorical',\n",
        "      target_size=(105,105,),\n",
        "      color_mode='rgb',\n",
        "      shuffle=True,\n",
        "      batch_size=batch_size    \n",
        "  )\n",
        "\n",
        "  val_generator = test_preprocessor.flow_from_directory(\n",
        "      val_data_path,  \n",
        "      class_mode='categorical',\n",
        "      target_size=(105,105,),\n",
        "      color_mode='rgb',\n",
        "      shuffle=False,\n",
        "      batch_size=batch_size    \n",
        "  )\n",
        "\n",
        "  # test_generator = test_preprocessor.flow_from_directory(\n",
        "  #     test_data_path,  \n",
        "  #     class_mode='categorical',|\n",
        "  #     target_size=(105,105,3),\n",
        "  #     color_mode='rgb',\n",
        "  #     shuffle=False,\n",
        "  #     batch_size=batch_size    \n",
        "  # )\n",
        "\n",
        "  return train_generator, val_generator"
      ],
      "metadata": {
        "id": "aex77Q29Fyea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_main = \"/content\"\n",
        "\n",
        "path_to_train = os.path.join(PATH_main, \"training_data/train\")\n",
        "path_to_val = os.path.join(PATH_main, \"training_data/val\")\n",
        "# path_to_test = os.path.join(PATH_main, \"Test\")\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_generator, val_generator = create_generators(batch_size, path_to_train, path_to_val)"
      ],
      "metadata": {
        "id": "3tMEeB_8GWZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compiling the model and fitting the data"
      ],
      "metadata": {
        "id": "tjFUtcDKG1qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_main = \"/content\"\n",
        "\n",
        "# callbacks\n",
        "path_to_save_model = os.path.join(PATH_main, \"Models\")\n",
        "\n",
        "ckpt_saver = ModelCheckpoint(\n",
        "    path_to_save_model,  \n",
        "    monitor=\"val_accuracy\",  \n",
        "    mode=\"max\",  \n",
        "    save_best_only=True,  \n",
        "    save_freq='epoch',  \n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor=\"val_accuracy\",  \n",
        "                               patience=10, verbose=1)\n",
        "\n",
        "# Reduce learning rate\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,patience=2, min_lr=1e-6)\n",
        "\n",
        "# CSV Log\n",
        "csv_logger = CSVLogger('training.log', separator=',', append=False)"
      ],
      "metadata": {
        "id": "busCg0A-G3Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nbr_classes = train_generator.num_classes\n",
        "model = class_model(nbr_classes)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "\n",
        "model.compile(optimizer=optimizer,  \n",
        "              loss='categorical_crossentropy',  \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_generator,  \n",
        "          epochs=50,  \n",
        "          batch_size=batch_size,  \n",
        "          validation_data=val_generator,  \n",
        "          callbacks=[ckpt_saver, early_stopping, reduce_lr, csv_logger])"
      ],
      "metadata": {
        "id": "WPKycJKtHcEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving model"
      ],
      "metadata": {
        "id": "GDeaBlmKNC6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !mv Models model_family_inceptionv3_all"
      ],
      "metadata": {
        "id": "7l-f2AsDIxgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r model_family_inceptionv3_all.zip model_family_inceptionv3_all"
      ],
      "metadata": {
        "id": "ZDgkY61p7y9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict test dataset"
      ],
      "metadata": {
        "id": "XmGgCEOU7_so"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TBppfyPS-Egv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load test set"
      ],
      "metadata": {
        "id": "d4QO9n0iCFQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# zip file from N'Sarm (Sauvola) \"TEST_Public\"\n",
        "!gdown --id \"1_tl4EXJkiFjJvHljIbCkZsebKlYqXJLP&export=download\""
      ],
      "metadata": {
        "id": "Wy4XuZo099Ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zip file from N'Sarm (Sauvola) \"TEST_Public_Private\"\n",
        "!gdown --id 1VUwIN1NYcuWmH6h19RBWM1Vm9H_gHckG&export=download"
      ],
      "metadata": {
        "id": "yiNqyXxWnNL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/TestSetFinalFinal.zip -d /content/"
      ],
      "metadata": {
        "id": "GVzNknhr-CWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define path for test dataset\n",
        "PATH_TEST = '/content/TestSetFinalFinal'\n",
        "file = os.listdir(PATH_TEST)\n",
        "print(len(file))\n",
        "print(file[0])"
      ],
      "metadata": {
        "id": "snS3Xg-A-PSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the file name (image Id)\n",
        "id = file[0].replace('.jpg', '')\n",
        "id"
      ],
      "metadata": {
        "id": "KUUwToqe-P1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# collect the image pixels\n",
        "\n",
        "img_list = []\n",
        "img_id = []\n",
        "for i in range(len(file)):\n",
        "    id = file[i].replace('.jpg', '')\n",
        "    img_id.append(id)\n",
        "    path_img = os.path.join(PATH_TEST, file[i])\n",
        "    img = cv2.imread(path_img)\n",
        "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # img = img[..., tf.newaxis]\n",
        "    img = img.astype(\"float32\") / 255.\n",
        "    # img = pad(img) # padding to the same size\n",
        "    # img_shape = img.shape\n",
        "    img_list.append(img)\n",
        "    \n",
        "    # img_shape_array.append(img_shape)\n",
        "    # print(img.shape)\n",
        "img_list = np.array(img_list)"
      ],
      "metadata": {
        "id": "HB8FhH8M-R2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(img_list[1].shape)\n",
        "print(img_id[1])"
      ],
      "metadata": {
        "id": "eHHniOpm-UG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_array = np.asarray(img_list)\n",
        "print(img_array.shape)"
      ],
      "metadata": {
        "id": "1Kbb1dd6-Vf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load saved model"
      ],
      "metadata": {
        "id": "2MIUkaEs-dUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PATH_model_Fam = \"/content/drive/MyDrive/font_Models/InceptionV3_all/model_family_inceptionv3_all\"\n",
        "# model_Fam = tf.keras.models.load_model(PATH_model_Fam)\n",
        "\n",
        "# PATH_model_Size = \"/content/drive/MyDrive/font_Models/InceptionV3_all/model_size_inceptionv3_all\"\n",
        "# model_Size = tf.keras.models.load_model(PATH_model_Size)\n",
        "\n",
        "PATH_model_Style = \"/content/drive/MyDrive/font_Models/InceptionV3_all/model_style_inception_all\"\n",
        "model_Style = tf.keras.models.load_model(PATH_model_Style)"
      ],
      "metadata": {
        "id": "EC_IvkXY-YMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del img_list"
      ],
      "metadata": {
        "id": "9_X6sXUJMSuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSVLogger to check the accuracy and loss history\n",
        "log_data = pd.read_csv('training.log', sep=',', engine='python')"
      ],
      "metadata": {
        "id": "6Xt4fxwxdzA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict the test image"
      ],
      "metadata": {
        "id": "x83V4lqY-iW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred_Fam = model_Fam.predict(img_array)\n",
        "# y_pred_Fam = np.argmax(y_pred_Fam, axis = 1)\n",
        "\n",
        "# y_pred_Size = model_Size.predict(img_array)\n",
        "# y_pred_Size = np.argmax(y_pred_Size, axis = 1)\n",
        "\n",
        "y_pred_Style = model_Style.predict(img_array)\n",
        "y_pred_Style = np.argmax(y_pred_Style, axis = 1)"
      ],
      "metadata": {
        "id": "1nXvTwbu-leS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_pred_Style)"
      ],
      "metadata": {
        "id": "6JZL9idi-piR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge predicted results from all labels"
      ],
      "metadata": {
        "id": "3LFHfjRO-rx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_zip = zip(img_id, y_pred_Fam, y_pred_Size, y_pred_Style)\n",
        "df_res = pd.DataFrame(res_zip, columns = ['Id', '', 'style-weight'])\n",
        "df_res.head()"
      ],
      "metadata": {
        "id": "wLkCi1Wg-p8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Re-label the encoded results"
      ],
      "metadata": {
        "id": "9GplN1eb-1jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_res = df_res.replace({'name' : {\n",
        "                            0 : 'Angsana_New',\n",
        "                            1 : 'Cordia_New',\n",
        "                            2 : 'DM_Shining_Star_Regular',\n",
        "                            3: 'FC_Knomphing_Regular',\n",
        "                            4:'Kunlasatri',\n",
        "                            5:'TH_Chakra_Petch',\n",
        "                            6:'TH_Charm_of_AU',\n",
        "                            7:'TH_Mali_Grade6',\n",
        "                            8:'TH_Sarabun',\n",
        "                            9:'fonttintin'},  \n",
        "                        'size' : {\n",
        "                                0 : '12px',\n",
        "                                1 : '14px',\n",
        "                                2 : '16px',\n",
        "                                3 : '18px',\n",
        "                                4 : '20px',\n",
        "                                5 : '22px',\n",
        "                                6 : '24px'},\n",
        "                        'style-weight' : {\n",
        "                                  0 : 'italic-bold',\n",
        "                                  1 : 'italic-normal',\n",
        "                                  2 : 'normal-bold',\n",
        "                                  3 : 'normal-normal'}\n",
        "                        })"
      ],
      "metadata": {
        "id": "3LEBDnMp-09Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_res.head()"
      ],
      "metadata": {
        "id": "NcKN2ugq_T-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_res['file'] = df_res['name'] + '.ttf'\n",
        "df_res['file'] = df_res['file'].replace('_', ' ', regex=True)\n",
        "df_res = df_res.reindex(columns=['Id', 'name', 'file', 'size'])\n",
        "df_res.head()"
      ],
      "metadata": {
        "id": "Ke1CdqFa_UxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_res.to_csv(\"csv_temp.csv\", index = False)"
      ],
      "metadata": {
        "id": "WEZjIzhEpm8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- If we cannot predict all features together, we will predict each feature, separately.\n",
        "- Then, we will read csv file for previous predicted results to merge with the latest one."
      ],
      "metadata": {
        "id": "2p5RQFRGJuZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp = pd.read_csv(\"csv_temp.csv\")"
      ],
      "metadata": {
        "id": "8t6IeFLYKI7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now, we add the latest prediction "
      ],
      "metadata": {
        "id": "rUPaWAO-KR7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp[\"style-weight\"] = df_res[\"style-weight\"]"
      ],
      "metadata": {
        "id": "MxtZQCTSO_V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The entired predictions must be contained in csv form."
      ],
      "metadata": {
        "id": "FxACnzLKKe2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_try = df_temp"
      ],
      "metadata": {
        "id": "q4BLbwXZLeGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NAME = pd.DataFrame(list(zip(df_try['Id']+ '_name', df_try['name'])), columns=['Id', 'Predicted'])\n",
        "FILE = pd.DataFrame(list(zip(df_try['Id']+ '_file', df_try['file'])), columns=['Id','Predicted'])\n",
        "SIZE = pd.DataFrame(list(zip(df_try['Id']+ '_size', df_try['size'])), columns=['Id','Predicted'])\n",
        "STYLE = pd.DataFrame(list(zip(df_try['Id']+ '_style-weight', df_try['style-weight'])), columns=['Id','Predicted'])"
      ],
      "metadata": {
        "id": "Y0xxzAu2_n7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(NAME))\n",
        "print(len(FILE))\n",
        "print(len(SIZE))\n",
        "print(len(STYLE))"
      ],
      "metadata": {
        "id": "SA7rR89C_pNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = pd.concat([NAME, FILE, SIZE, STYLE], axis=0)"
      ],
      "metadata": {
        "id": "7t3P7MHF_qoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The sample submission file, imported from Kaggle, is used as referenced index columns."
      ],
      "metadata": {
        "id": "MncmFV0HLixq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "df_sub.head()"
      ],
      "metadata": {
        "id": "WbXCdRUy_YXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_results = pd.merge(df_sub, df_final, on='Id', how=\"outer\")"
      ],
      "metadata": {
        "id": "zmHr1-Ra_sX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_results.shape"
      ],
      "metadata": {
        "id": "fsdn5D0L_xfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_results = final_results.drop(columns=['Predicted_x'])"
      ],
      "metadata": {
        "id": "SnzxudI0_353"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_results.rename(columns={'Predicted_y': 'Predicted'}).to_csv('submission_Inception_Test2.csv', index=False, encoding='utf8')"
      ],
      "metadata": {
        "id": "PQUg_UwE_5J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merging two test results from public and private round"
      ],
      "metadata": {
        "id": "fBKATilgL5P7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test1 = pd.read_csv(\"/content/submission_Inception_Test1.csv\")  # public\n",
        "test2 = pd.read_csv(\"/content/submission_Inception_Test2.csv\")  # private"
      ],
      "metadata": {
        "id": "rpQmb8hiuj05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.merge(test1, test2, on=['Id'], how=\"outer\")"
      ],
      "metadata": {
        "id": "6Syr2aLIwu58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_csv(\"/content/submission_Inception_Test_Final.csv\", index=False)"
      ],
      "metadata": {
        "id": "CN0VI-Be0dQL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}